<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Body • Ethics of AI</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

<header class="site">
  <div class="container brand">
    <h1>Ethics of AI in Programming & Technological Sectors</h1>
    <p>Grade 12 | Computer Applications Technology | <span class="badge">Detailed & Formal</span></p>
    <nav class="menu">
      <a href="index.html">Home</a>
      <a href="introduction.html">Introduction</a>
      <a href="body.html">Body</a>
      <a href="conclusion.html">Conclusion</a>
      <a href="references.html">References</a>
    </nav>
  </div>
</header>

  <div class="container">
    <main class="panel">
      <h2>Key Ethical Issues and Practical Responses</h2>

      <h3>1) Fairness and Bias</h3>
      <p>
        Machine‑learning models learn patterns from historical data. If those data reflect unequal treatment or
        under‑representation, models can reproduce or amplify unfair outcomes. Examples include screening tools
        that disadvantage certain groups in hiring or lending decisions. Ethical development requires diverse,
        high‑quality datasets, bias testing, and measurable fairness targets during development and deployment.
      </p>

      <h3>2) Privacy and Data Protection</h3>
      <p>
        AI often relies on large volumes of personal information. Responsible practice includes collecting only
        what is necessary, securing data, and respecting consent and purpose limits. Documentation should explain
        how data are sourced, stored, anonymised or deleted, and how individuals can exercise their rights.
      </p>

      <figure>
        <img src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Scales_of_Justice.png" alt="Scales of justice symbolising fairness and accountability">
        <figcaption>Image: Wikimedia Commons (Scales of Justice)</figcaption>
      </figure>

      <h3>3) Transparency and ExplAINability</h3>
      <p>
        Users and affected stakeholders should understand how important decisions are made. Options include
        simplified model cards, user‑facing explanations, and traceable logs. While not every model is fully
        explainable, teams can document design choices, known limitations, and appropriate use contexts.
      </p>

      <h3>4) Accountability and Governance</h3>
      <p>
        Clear accountability ensures someone is responsible for performance, safety and compliance. Good practice
        includes assigning system owners, independent reviews, audit trails, and incident response plans.
        Contracts and policies should define responsibilities between developers, deployers and clients.
      </p>

      <h3>5) Safety, Security and Misuse</h3>
      <p>
        Systems should be robust against failures and adversarial abuse (e.g., prompt injection, data poisoning,
        model theft). Security testing, red‑teaming, rate‑limiting, and monitoring help prevent misuse, while
        human oversight can intervene when harms are detected.
      </p>

      <h3>6) Labour and Economic Impacts</h3>
      <p>
        Automation can increase productivity but also displace certain roles. Ethical adoption plans include
        workforce consultation, upskilling and reskilling, and transparent communication about how AI will
        change work processes.
      </p>

      <h3>7) Academic Integrity and Intellectual Property</h3>
      <p>
        Generative AI can enable plagiarism or unauthorised reuse of copyrighted content. Responsible use policies,
        citation guidance, and tooling to detect misconduct help preserve integrity. Developers should respect
        licensing terms of data and software components.
      </p>

      <h3>8) Environmental Considerations</h3>
      <p>
        Training and serving large models consume energy and water. Mitigations include efficient architectures,
        using greener hosting options, and aligning model sizes to real needs rather than defaulting to the
        largest possible systems.
      </p>

      <h2>Good Practices for Developers and Organisations</h2>
      <div class="grid">
        <div class="card">
          <h3>Data Governance</h3>
          <ul class="checked">
            <li>Define lawful purpose and data minimisation.</li>
            <li>Track provenance; assess quality and representativeness.</li>
            <li>Plan retention, deletion and subject‑rights processes.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Model Documentation</h3>
          <ul class="checked">
            <li>Maintain model cards: intended use, limits, metrics.</li>
            <li>Record versions, training data scope, evaluation results.</li>
            <li>Specify prohibited uses and escalation contacts.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Evaluation & Monitoring</h3>
          <ul class="checked">
            <li>Test accuracy, robustness and fairness before release.</li>
            <li>Monitor in production for drift and incidents.</li>
            <li>Provide user feedback channels; act on issues quickly.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Human Oversight</h3>
          <ul class="checked">
            <li>Keep a human in the loop for high‑risk decisions.</li>
            <li>Enable contestability and appeal mechanisms.</li>
            <li>Pause or roll back when thresholds are breached.</li>
          </ul>
        </div>
      </div>
    </main>
  </div>

<footer class="site">
  <div class="container">
    <p>&copy; 2025 • Research Project • Ethics of AI</p>
  </div>
</footer>

</body>
</html>
